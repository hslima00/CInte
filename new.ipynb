{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs that we'll need for the project: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import operator\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from funcs import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to ignore warnings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the project into steps\n",
    "\n",
    "1. Read the file\n",
    "2. Remove Outliers  \n",
    "   1. Quartiles\n",
    "   2. Deviation \n",
    "   3. By hand in special cases \n",
    "3. Normalization and standardization of the data\n",
    "   1. Z-Score\n",
    "   2. Min Max\n",
    "4. Split the data into train, test and validation sets\n",
    "5. Train the NN\n",
    "6. Adjust parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file and analyze data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(\"Proj1_Dataset.csv\", sep=\",\", decimal=\".\")\n",
    "\n",
    "data_df=parse_date_time(data_df)\n",
    "\n",
    "data_df.to_csv(\"Proj1_Dataset_changed.csv\")\n",
    "\n",
    "#plot_data(data_df, temperature=True, CO2=True, PIR=True, light=True)\n",
    "\n",
    "#scatter_plot(data_df, temperature=False, C02_PIR=False, light=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outliers and Interpolate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S1Temp        S2Temp        S3Temp       S1Light       S2Light  \\\n",
      "count  10128.000000  10127.000000  10129.000000  10129.000000  10129.000000   \n",
      "mean      20.424883     20.553337     20.003294     62.218185     58.250864   \n",
      "std        0.415856      0.663691      0.543616    131.357611    142.220513   \n",
      "min        0.000000     19.660000    -12.320000      0.000000      0.000000   \n",
      "25%       20.130000     20.140000     19.650000      0.000000      0.000000   \n",
      "50%       20.330000     20.340000     19.910000      0.000000      0.000000   \n",
      "75%       20.672500     20.700000     20.310000     28.000000     30.000000   \n",
      "max       21.380000     24.000000     21.180000   5500.000000    516.000000   \n",
      "\n",
      "            S3Light           CO2          PIR1          PIR2       Persons  \n",
      "count  10129.000000  10128.000000  10129.000000  10129.000000  10129.000000  \n",
      "mean      80.774706    474.081754      0.107612      0.094382      0.452068  \n",
      "std      661.501771    204.196690      0.309905      0.292375      0.940729  \n",
      "min        0.000000    345.000000      0.000000      0.000000      0.000000  \n",
      "25%        0.000000    355.000000      0.000000      0.000000      0.000000  \n",
      "50%        0.000000    360.000000      0.000000      0.000000      0.000000  \n",
      "75%      114.000000    531.250000      0.000000      0.000000      0.000000  \n",
      "max    65536.000000   1270.000000      1.000000      1.000000      3.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using ´describe()´ we realized the following:\n",
    "\n",
    "- The dataframe is 10129 rows long and some values return a count of, for example, 10127 rows, therefore we need to fill in the data where this values are missing \n",
    "- If we look closely to the mean and max values of each collumn we realize that there are some outliers due to the discrepancy of the values. Due to the ammount of data we'll simply drop the entire row where the value is found. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed outlined from index  56 from  S1Temp with value of: 0.0\n",
      "Removed outlined from index  1188 from  S3Temp with value of: -12.32\n",
      "Removed outlined from index  3760 from  S1Light with value of: 5500\n",
      "Removed outlined from index  2800 from  S3Light with value of: 65536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_df = drop_outliners(data_df, threshold=6,\n",
    "                         collumn_to_remove_outliers=\n",
    "                         [\"S1Temp\", \"S2Temp\",\"S3Temp\",\n",
    "                          \"CO2\",\"PIR1\", \"PIR2\",\"S1Light\",\n",
    "                           \"S2Light\",\"S3Light\"])\n",
    "\n",
    "\n",
    "#plot_data(data_df, temperature=True, CO2=True, PIR=True, light=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpolate NaN values\n",
    "data_df = data_df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data with Min Max \n",
    "\n",
    "#plot_data(data_df, temperature=True, CO2=True, PIR=True, light=True)\n",
    "\n",
    "# split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test sets\n",
    "train, test = train_test_split(data_df, test_size=0.3, shuffle=True)\n",
    "test, val = train_test_split(test, test_size=0.3, shuffle=True)\n",
    "# split into input and ou\n",
    "y_train_df = train['Persons']\n",
    "x_train_df = train.drop(['Persons'], axis=1)\n",
    "y_test_df = test['Persons']\n",
    "x_test_df = test.drop(['Persons'], axis=1)      \n",
    "y_val_df = val['Persons']\n",
    "x_val_df = val.drop(['Persons'], axis=1)\n",
    "\n",
    "\n",
    "x_train_df, x_train_df_min, x_train_df_max = normalize_train_set(x_train_df)\n",
    "x_test_df = normalize_test_set(x_test_df, x_train_df_min, x_train_df_max)\n",
    "x_val_df = normalize_test_set(x_val_df, x_train_df_min, x_train_df_max)\n",
    "#plot_data(x_test_df, temperature=True, CO2=True, light=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912\n",
      "2126\n",
      "Validate\n",
      "Accuracy: 0.9802631578947368\n",
      "Precision: 0.9523637021892835\n",
      "Recall: 0.9411683266620237\n",
      "Confusion:\n",
      " [[697   0   0   1]\n",
      " [  2  42   1   0]\n",
      " [  0   1  82   4]\n",
      " [  1   0   8  73]]\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "Accuracy: 0.9873000940733773\n",
      "Precision: 0.9627566085636741\n",
      "Recall: 0.966238940499258\n",
      "Confusion:\n",
      " [[1651    4    0    2]\n",
      " [   1  103    1    2]\n",
      " [   0    0  176    8]\n",
      " [   2    0    7  169]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# define model\n",
    "#Config: {'activation': 'relu', 'hidden_layer_sizes': (30, 70), 'learning_rate': 'constant', 'learning_rate_init': 0.1, 'max_iter': 30, 'solver': 'sgd'}\n",
    "model = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=([7,5]), random_state=21, learning_rate_init=0.04)\n",
    "#it uses default the relu to activation\n",
    "\n",
    "    \n",
    "#7,5 (bons resultados)\n",
    "\n",
    "\n",
    "# fit model ignoring DateTime column\n",
    "#drop DateTime column\n",
    "\n",
    "x_train_df = x_train_df.drop(['DateTime'], axis=1)\n",
    "x_val_df = x_val_df.drop(['DateTime'], axis=1)\n",
    "x_test_df = x_test_df.drop(['DateTime'], axis=1)\n",
    "\n",
    "model.fit(x_train_df, y_train_df)\n",
    "\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "y_val_pred = model.predict(x_val_df)\n",
    "\n",
    "print(len(y_val_pred))\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test_df)\n",
    "print(len(y_pred))\n",
    "\n",
    "print(\"Validate\")\n",
    "print(\"Accuracy:\",accuracy_score(y_val_df, y_val_pred))\n",
    "print(\"Precision:\",precision_score(y_val_df, y_val_pred, average='macro'))\n",
    "print(\"Recall:\",recall_score(y_val_df, y_val_pred, average='macro'))\n",
    "print(\"Confusion:\\n\",confusion_matrix(y_val_df, y_val_pred))   \n",
    "print(\"\\n\\n\")\n",
    "print(\"Test\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test_df, y_pred))\n",
    "print(\"Precision:\",precision_score(y_test_df, y_pred, average='macro'))\n",
    "print(\"Recall:\",recall_score(y_test_df, y_pred, average='macro'))\n",
    "print(\"Confusion:\\n\",confusion_matrix(y_test_df, y_pred))    \n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
